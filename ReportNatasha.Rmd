---
title: "Title"
author: "R.H; S.Y "
date: "Tuesday, Feb 03, 2015"
output:
  pdf_document:
    fig_height: 11
    fig_width: 8
    number_sections: yes
---

```{r knitr_options, include=FALSE}
library(knitr)
opts_chunk$set(include = FALSE,echo = FALSE, eval = FALSE)
```

```{r read_data}
rm(list = ls())
## read 0\1 data:
ZO_data <- read.csv(file = "Oct29_2014_Xray_B6N_MGPSelect_Oor1_cleanV2.csv") # 8176 rows ,79 columns 

## 46 variables of interest:
XrayVariableList <- c("Number.Of.Thoracic.Vertebrae","Number.Of.Lumbar.Vertebrae","Number.Of.Pelvic.Vertebrae","Number.Of.Caudal.Vertebrae", "Transitional.Vertebrae" , "Shape.Of.Vertebrae","Fusion.Of.Vertebrae", "Processes.On.Vertebrae","Maxilla","Zygomatic.Bone","Number.Of.Cervical.Vertebrae","Skull.Shape","Number.Of.Ribs.Right","Number.Of.Ribs.Left","Shape.Of.Ribcage","Shape.Of.Ribs","Rib.Fusions","Clavicle","Scapula"  ,"Humerus","Radius","Ulna","Pelvis","Femur","Tibia","Fibula","Joints","Shape.Of.Spine","Teeth","Mandible","Number.Of.Digits","Digit.Integrity","Syndactylism","Polysyndactylism","Brachydactylism","Kyphosis","Lordosis","Scoliosis","Spinous.Processes","Transverse.Processes","Fusion.Processes","Caudal.Processes","Cervical.Processes","Lumbar.Processes","Sacral.Processes","Thoracic.Processes")    

## remove 3 variables with no values:
XrayVariableList_c <- XrayVariableList[!(XrayVariableList %in% c("Spinous.Processes","Transverse.Processes","Processes.On.Vertebrae"))]

## remove 3 cases with all NA's; remove variables not in the list:
ZO_data1 <- ZO_data[-which(apply(ZO_data[XrayVariableList_c],1,function(x) all(is.na(x))))
,c("Colony.Prefix","Genotype2","Genotype",XrayVariableList_c)]

## number of mices in each KO group (except WT group)
n_t     <- aggregate(. ~ Genotype2 + Colony.Prefix, data = ZO_data1, subset = Genotype2 !="WT",function(x) sum(!is.na(x)),na.action=NULL)

## number of NAs in each KO group (except WT group)
na_KO <- aggregate(. ~ Genotype2 + Colony.Prefix, data = ZO_data1, subset = Genotype2 !="WT", function(x) sum(is.na(x)),na.action=NULL)

## number of mices-marked-with-one in each KO group (except WT group)
n <- aggregate(. ~ Genotype2 + Colony.Prefix,data = ZO_data1,subset = Genotype2 !="WT",
               sum, na.action=NULL, na.rm=T)

## the number of mices in the WT group
N_minus_n_t <- aggregate(. ~ Genotype2 ,data = ZO_data1,subset = Genotype2 =="WT",
                         function(x) sum(!is.na(x)),na.action=NULL)

## number NAs in the WT group
na_WT <- aggregate(. ~ Genotype2 ,data = ZO_data1,subset = Genotype2 =="WT",
                         function(x) sum(is.na(x)),na.action=NULL)

## number of mices-marked-with-one in the WT
n_u_minus_n <- aggregate(. ~ Genotype2 ,data = ZO_data1,subset = Genotype2 =="WT",
                         sum, na.action=NULL, na.rm=T)

### Objects dimensions and descriptions:
## n           : 473 X 43 - number of faulted mice in each of the 473 KO (rows) in each outcome (columns)
## n_t         : 473 X 43 - number of tested  mice in each of the 473 KO (rows) in each outcome (columns)
## n_u_minus_n : 1 X 43   - number of faulted WT in each outcome (columns)
## N_minus_n_t : 1 X 43   - number of tested  WT in each outcome (columns)
## na_KO       : 473 X 43 - number of NAs in each KO and outcome
## na_WT       : 1 X 43   - number of NAs in WT for each outcome
### more notations:
## n_u - faulted mice in total
## B   - last value in the support of HG distribution, is min{n_t,n_u} - the minimum between total faults in both groups and tested mice in KO group
```

```{r aggregate_over_all_outcomes}
## reshape data for analysis of all KO together
vec_n_t         <- as.vector(as.matrix(n_t[-(1:3)]))
vec_na_KO       <- as.vector(as.matrix(na_KO[-(1:3)]))
vec_n           <- as.vector(as.matrix(n[-(1:3)]))
vec_N_minus_n_t <- rep(as.vector(as.matrix(N_minus_n_t[-(1:3)])),each=nrow(n))
vec_na_WT       <- rep(as.vector(as.matrix(na_WT[-(1:3)])),each=nrow(n))
vec_n_u_minus_n <- rep(as.vector(as.matrix(n_u_minus_n[-(1:3)])),each=nrow(n))

# ## reference:
# a=matrix(1:15,ncol=3)
# 
# dimnames(a) <- list("KO"=1:5,"OUTCOMES"=1:3)
# a
# (va <- as.vector(a))
# 
# b=matrix(c(1,6,11),ncol=3)
# b
# (vb <- as.vector(b))
# 
# rbind(va,vb) # not desired result
# 
# repb <- rep(vb, each=nrow(a)) # use 'each' argument
# 
# rbind(va,repb) # OK

```

```{r functions}
# ---------------- functions and parameters: --------------------------------
lambda <- 0.05

## function to calculate the size of the Tarone family,
## finds K(alpha)=inf{1:j|m(alpha,j)<=j} where m(alpha,j)=#{i|alpha_star[i]<=alpha/j}
findK <- function(alpha_star,alpha=0.05,verbose=T)
{
  la    <- length(alpha_star) 
  m     <- vector(length=la)
  for (j in 1:la)    m[j] <- sum(alpha_star<=(alpha/j))
  K <- (1:la)[which(m<=(1:la))[1]]
  if (is.na(K)) stop("something is wrong, check alpha_star for NAs and findK() definition")
  if (verbose) cat("K = ",K,"\n")
  return (K)
}

# estimate pi0 conditional expectation over U[0,1]:
Pi_0_est_EU <- function(p,f_n,kappa,in_fam,lambda)
{
  ## size of the sub-family:
  m_tag <- sum(in_fam)
  ## logical vector of size of in_fam that indicates where p-value is between lambda and lambda + next step in pdf:
  lpl <- (lambda < p[in_fam]) & (p[in_fam] <= lambda + kappa[in_fam]*f_n[in_fam])
  ## formula for the conditional expectation over uniform (0,1):
  ecdf_lambda_EU <- (sum(p[in_fam]<=lambda))/m_tag + (sum(1 - (p[in_fam][lpl]-lambda) / (kappa[in_fam][lpl]*f_n[in_fam][lpl]) ))/m_tag
  ## and the expectation of the pi_0 estimate
  Pi_0_hat_EU <- (1-ecdf_lambda_EU)/(1-lambda)
  return(Pi_0_hat_EU)
}

# pi0 estimation
pi_0_est_rand <- function(p_rand, in_fam, lambda)
  sum(lambda<p_rand[in_fam])/(1-lambda)/sum(in_fam)

# adaptive BH  
p_adjust_adaptive <- function(p,pi_0_hat)
{
  lp <- length(p)
  i <- lp:1L
  o <- order(p, decreasing = TRUE)
  ro <- order(o)
  pmin(1, cummin(lp*pi_0_hat/i * p[o]))[ro]
}

## print 2X2 table for outcome j and KO i:
ptable <- function(i,j)
{
  n_u1 <- n_u_minus_n[1,3+j]+n[i,3+j]
  N1 <- N_minus_n_t[1,3+j] + n_t[i,3+j]
  n_t1 <- n_t[i,3+j]
  n1  <- n[i,3+j]
  tb <- matrix(c(n1     ,n_u1-n1       ,  n_u1,
               n_t1-n1,N1-n_t1-n_u1+n1,N1-n_u1,
               n_t1   ,N1-n_t1        ,N1),
               nrow=3,ncol=3,byrow=T)
  dimnames(tb) <- list("Defected"=c("Y","N","TOTAL"),
                       "Group"=c("KO","WT","TOTAL"))
  tbna <- matrix(c(na_KO[i,3+j],na_WT[1,3+j],na_KO[i,3+j]+na_WT[i,3+j]),nrow=1,ncol=3,byrow=T)
  dimnames(tbna) <- list("#NAs","Group"=c("KO","WT","TOTAL"))
  return(tb)
}

```

```{r all_outcomes_together}
# ---------------- get statistics and pv: --------------------------------

## work with phyper() notation:
mm <- vec_n_u_minus_n + vec_n
nn <- vec_N_minus_n_t + vec_n_t - mm
kk  <- vec_n_t
BB  <- pmin(mm,kk)
stopifnot(vec_n<=BB)
xx  <- pmin(vec_n,BB)

## get pv (right tail) and alpha star:
p  <- dhyper(x = xx, m = mm, n = nn, k = kk) + phyper(q = xx, m = mm, n = nn, k = kk, lower.tail = FALSE)
alpha_star <- dhyper(x=BB, m = mm, n = nn, k = kk)

## get highest pdf value within the pv region:
f_n <- dhyper(x = xx, m = mm, n = nn, k = kk)
## get number of occurences of this highest value (usually one):
kappa <- apply(cbind(BB,mm,nn,kk,f_n),1,
             function(x) sum(dhyper(x = 0:x[1], m = x[2], n = x[3], k = x[4])==x[5]))
set.seed(1)
u <- runif(n=length(f_n))
p_rand <- p-u*kappa*f_n

# ---------- Adjustment 1 p -------------------

## BH adjustment:
pa_BH              <- p.adjust(p,"BH")

## BH on "minimum attainable pv" ( alpha_star) smaller than 0.05:
F_0.05             <- alpha_star<=0.05
size_F_0.05        <- sum(F_0.05)
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p.adjust(p[F_0.05],"BH")

## BH on Tarone family:
K               <- 12125# findK(alpha_star)
F_Gilb          <- alpha_star<=0.05/K
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p.adjust(p[F_Gilb],"BH")

## estimation of m1 for each sub-family thresholded by alpha_star
t <- sort(alpha_star)
# m1_hat <-  size_F <- p1_hat <- rep(NA,length(t))
# for (j in 1:length(t))
# {
#   in_fam <- alpha_star <= t[j]
#   size_F[j] <- sum(in_fam)
#   Pi_0_hat_EU <- Pi_0_est_EU(p = p,f_n = f_n,kappa = kappa,in_fam = in_fam,lambda = lambda)
#   m1_hat[j] <- size_F[j]*(1-Pi_0_hat_EU)
#   p1_hat[j] <- (1-Pi_0_hat_EU)
#   if (!(j%%100)) cat(j,"\n")
# }
# save(m1_hat,p1_hat,size_F,file = "m1p1sizeF_1.RData")

load(file = "m1p1sizeF_1.RData")
# choice of optimum sub family:
argmax_m1_hat <-  which.max(m1_hat)
F_new <- alpha_star <= t[argmax_m1_hat]
size_F_new <- sum(F_new)
pa_new <- rep(1,length(F_new))
pa_new[F_new] <- p.adjust(p[F_new],"BH")

# estimation of m1 for each sub-family thresholded by alpha_star
threshold <- 0.05
A_size_F <- length(p)
iter <- 0
while(T){
cat(iter,"\n")
if (A_size_F == sum(alpha_star <= threshold)) break
in_fam <- alpha_star <= threshold
A_size_F <- sum(in_fam)
if (A_size_F==0) break
A_Pi_0_hat_EU <- Pi_0_est_EU(p = p,f_n = f_n,kappa = kappa,in_fam = in_fam,lambda = lambda)
A_m1_hat <- A_size_F*(1-A_Pi_0_hat_EU)
threshold <- A_m1_hat/A_size_F*0.05/0.95
iter <- iter + 1
}
F_newA <- in_fam
size_F_newA <- sum(F_newA)
pa_newA <- rep(1,length(F_newA))
pa_newA[F_newA] <- p.adjust(p[F_newA],"BH")

# summaries rejections: 
c1 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))
fam_size <- c(length(p),size_F_0.05,K,size_F_new,A_size_F)

# ---------- Adjustment 2 : p adaptive (m0 estimation) lambda 0.05-------------------
## BH adjustment:
pi_0_all  <-  pi_0_est_rand(p_rand = p_rand, in_fam = rep(T,length(p_rand)),lambda = lambda)
pa_BH              <- p_adjust_adaptive(p = p, pi_0_hat = pi_0_all)

pi_0_0.05      <- pi_0_est_rand(p_rand = p_rand, in_fam = F_0.05,lambda = lambda)
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p_adjust_adaptive(p = p[F_0.05], pi_0_hat = pi_0_0.05)

pi_0_Tar   <- pi_0_est_rand(p_rand = p_rand, in_fam = F_Gilb,lambda = lambda)
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p_adjust_adaptive(p = p[F_Gilb], pi_0_hat = pi_0_Tar)

pi_0_new   <- pi_0_est_rand(p_rand = p_rand, in_fam = F_new,lambda = lambda)
pa_new         <- rep(1,length(F_new))
pa_new[F_new] <- p_adjust_adaptive(p = p[F_new], pi_0_hat = pi_0_new)

pi_0_newA   <- pi_0_est_rand(p_rand = p_rand, in_fam = F_newA,lambda = lambda)
pa_newA         <- rep(1,length(F_newA))
pa_newA[F_newA] <- p_adjust_adaptive(p = p[F_newA], pi_0_hat = pi_0_newA)

# summaries rejections: 
c2 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))
pi0 <- c(pi_0_all,pi_0_0.05,pi_0_Tar,pi_0_new,pi_0_newA)

# ---------- Adjustment 3-4 mid pv -------------------
p_mid <- p - f_n*0.5
p_ <- p_mid
pa_BH              <- p.adjust(p_,"BH")
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p.adjust(p_[F_0.05],"BH")
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p.adjust(p_[F_Gilb],"BH")
pa_new <- rep(1,length(F_new))
pa_new[F_new] <- p.adjust(p_[F_new],"BH")
pa_newA <- rep(1,length(F_newA))
pa_newA[F_newA] <- p.adjust(p_[F_newA],"BH")
c3 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))
pa_BH              <- p_adjust_adaptive(p = p_, pi_0_hat = pi_0_all)
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p_adjust_adaptive(p = p_[F_0.05], pi_0_hat = pi_0_0.05)
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p_adjust_adaptive(p = p_[F_Gilb], pi_0_hat = pi_0_Tar)
pa_new          <- rep(1,length(F_new))
pa_new[F_new]   <- p_adjust_adaptive(p = p_[F_new], pi_0_hat = pi_0_new)
pa_newA         <- rep(1,length(F_newA))
pa_newA[F_newA] <- p_adjust_adaptive(p = p_[F_newA], pi_0_hat = pi_0_newA)
c4 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))

# ---------- Adjustment 5-6 p randomized 1 -------------------
set.seed(2)
u <- runif(n=length(f_n))
p_rand_1 <- p-u*kappa*f_n

p_ <- p_rand_1
pa_BH              <- p.adjust(p_,"BH")
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p.adjust(p_[F_0.05],"BH")
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p.adjust(p_[F_Gilb],"BH")
pa_new <- rep(1,length(F_new))
pa_new[F_new] <- p.adjust(p_[F_new],"BH")
pa_newA <- rep(1,length(F_newA))
pa_newA[F_newA] <- p.adjust(p_[F_newA],"BH")
c5 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))
pa_BH              <- p_adjust_adaptive(p = p_, pi_0_hat = pi_0_all)
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p_adjust_adaptive(p = p_[F_0.05], pi_0_hat = pi_0_0.05)
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p_adjust_adaptive(p = p_[F_Gilb], pi_0_hat = pi_0_Tar)
pa_new          <- rep(1,length(F_new))
pa_new[F_new]   <- p_adjust_adaptive(p = p_[F_new], pi_0_hat = pi_0_new)
pa_newA         <- rep(1,length(F_newA))
pa_newA[F_newA] <- p_adjust_adaptive(p = p_[F_newA], pi_0_hat = pi_0_newA)
c6 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))

# ---------- Adjustment 7-8 p randomized 2 -------------------
set.seed(3)
u <- runif(n=length(f_n))
p_rand_2 <- p-u*kappa*f_n

p_ <- p_rand_2
pa_BH              <- p.adjust(p_,"BH")
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p.adjust(p_[F_0.05],"BH")
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p.adjust(p_[F_Gilb],"BH")
pa_new <- rep(1,length(F_new))
pa_new[F_new] <- p.adjust(p_[F_new],"BH")
pa_newA <- rep(1,length(F_newA))
pa_newA[F_newA] <- p.adjust(p_[F_newA],"BH")
c7 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))
pa_BH              <- p_adjust_adaptive(p = p_, pi_0_hat = pi_0_all)
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p_adjust_adaptive(p = p_[F_0.05], pi_0_hat = pi_0_0.05)
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p_adjust_adaptive(p = p_[F_Gilb], pi_0_hat = pi_0_Tar)
pa_new          <- rep(1,length(F_new))
pa_new[F_new]   <- p_adjust_adaptive(p = p_[F_new], pi_0_hat = pi_0_new)
pa_newA         <- rep(1,length(F_newA))
pa_newA[F_newA] <- p_adjust_adaptive(p = p_[F_newA], pi_0_hat = pi_0_newA)
c8 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))
#
tb_all <- cbind(fam_size,pi0,c1,c2,c3,c4,c5,c6,c7,c8)
save(tb_all,file="tb_all.RData")

```

```{r main_function}
proc1 <- function(j)
{
# ---------------- get statistics and pv: --------------------------------

## work with phyper() notation:
mm <- vec_n_u_minus_n + vec_n
nn <- vec_N_minus_n_t + vec_n_t - mm
kk  <- vec_n_t
BB  <- pmin(mm,kk)
stopifnot(vec_n<=BB)
xx  <- pmin(vec_n,BB)

## get pv (right tail) and alpha star:
p  <- dhyper(x = xx, m = mm, n = nn, k = kk) + phyper(q = xx, m = mm, n = nn, k = kk, lower.tail = FALSE)
alpha_star <- dhyper(x=BB, m = mm, n = nn, k = kk)

## get highest pdf value within the pv region:
f_n <- dhyper(x = xx, m = mm, n = nn, k = kk)
## get number of occurences of this highest value (usually one):
kappa <- apply(cbind(BB,mm,nn,kk,f_n),1,
             function(x) sum(dhyper(x = 0:x[1], m = x[2], n = x[3], k = x[4])==x[5]))
set.seed(j)
u <- runif(n=length(f_n))
p_rand <- p-u*kappa*f_n

# ---------- Adjustment 1 p -------------------

## BH adjustment:
pa_BH              <- p.adjust(p,"BH")

## BH on "minimum attainable pv" ( alpha_star) smaller than 0.05:
F_0.05             <- alpha_star<=0.05
size_F_0.05        <- sum(F_0.05)
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p.adjust(p[F_0.05],"BH")

## BH on Tarone family:
K               <- findK(alpha_star)
F_Gilb          <- alpha_star<=0.05/K
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p.adjust(p[F_Gilb],"BH")

## estimation of m1 for each sub-family thresholded by alpha_star
t <- sort(alpha_star)
m1_hat <-  size_F <- p1_hat <- rep(NA,length(t))
for (k in 1:length(t))
{
  in_fam <- alpha_star <= t[k]
  size_F[k] <- sum(in_fam)
  Pi_0_hat_EU <- Pi_0_est_EU(p = p,f_n = f_n,kappa = kappa,in_fam = in_fam,lambda = lambda)
  m1_hat[k] <- size_F[k]*(1-Pi_0_hat_EU)
  p1_hat[k] <- (1-Pi_0_hat_EU)
}

m1_hat_mat <<- cbind(m1_hat_mat,m1_hat)
p1_hat_mat <<- cbind(p1_hat_mat,p1_hat)

# choice of optimum sub family:
argmax_m1_hat <-  which.max(m1_hat)
F_new <- alpha_star <= t[argmax_m1_hat]
size_F_new <- sum(F_new)
pa_new <- rep(1,length(F_new))
pa_new[F_new] <- p.adjust(p[F_new],"BH")

# estimation of m1 for each sub-family thresholded by alpha_star
threshold <- 0.05
A_size_F <- length(p)
iter <- 0
while(T){
cat(iter,"\n")
if (A_size_F == sum(alpha_star <= threshold)) break
in_fam <- alpha_star <= threshold
A_size_F <- sum(in_fam)
if (A_size_F==0) break
A_Pi_0_hat_EU <- Pi_0_est_EU(p = p,f_n = f_n,kappa = kappa,in_fam = in_fam,lambda = lambda)
A_m1_hat <- A_size_F*(1-A_Pi_0_hat_EU)
threshold <- A_m1_hat/A_size_F*0.05/0.95
iter <- iter + 1
if (iter>30) 
  {
  cat ("~~~~~~~~~~~~",j,"~~~~~~~~","\n")
  break
  }
}
F_newA <- in_fam
size_F_newA <- sum(F_newA)
pa_newA <- rep(1,length(F_newA))
pa_newA[F_newA] <- p.adjust(p[F_newA],"BH")

# summaries rejections: 
c1 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))
fam_size <- c(length(p),size_F_0.05,K,size_F_new,A_size_F)

# ---------- Adjustment 2 : p adaptive (m0 estimation) lambda 0.05-------------------
## BH adjustment:
pi_0_all  <-  pi_0_est_rand(p_rand = p_rand, in_fam = rep(T,length(p_rand)),lambda = lambda)
pa_BH              <- p_adjust_adaptive(p = p, pi_0_hat = pi_0_all)

## BH on "minimum attainable pv" ( alpha_star) smaller than 0.05:
pi_0_0.05      <- pi_0_est_rand(p_rand = p_rand, in_fam = F_0.05,lambda = lambda)
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p_adjust_adaptive(p = p[F_0.05], pi_0_hat = pi_0_0.05)

## BH on Tarone family:
pi_0_Tar   <- pi_0_est_rand(p_rand = p_rand, in_fam = F_Gilb,lambda = lambda)
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p_adjust_adaptive(p = p[F_Gilb], pi_0_hat = pi_0_Tar)

## estimation of m1 for each sub-family thresholded by alpha_star
pi_0_new   <- pi_0_est_rand(p_rand = p_rand, in_fam = F_new,lambda = lambda)
pa_new         <- rep(1,length(F_new))
pa_new[F_new] <- p_adjust_adaptive(p = p[F_new], pi_0_hat = pi_0_new)

## estimation of m1 for each sub-family thresholded by alpha_star
pi_0_newA   <- pi_0_est_rand(p_rand = p_rand, in_fam = F_newA,lambda = lambda)
pa_newA         <- rep(1,length(F_newA))
pa_newA[F_newA] <- p_adjust_adaptive(p = p[F_newA], pi_0_hat = pi_0_newA)

# summaries rejections: 
c2 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))
pi0 <- c(pi_0_all,pi_0_0.05,pi_0_Tar,pi_0_new,pi_0_newA)

# ---------- Adjustment 3-4 mid pv -------------------
p_mid <- p - f_n*0.5
p_ <- p_mid
pa_BH              <- p.adjust(p_,"BH")
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p.adjust(p_[F_0.05],"BH")
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p.adjust(p_[F_Gilb],"BH")
pa_new <- rep(1,length(F_new))
pa_new[F_new] <- p.adjust(p_[F_new],"BH")
pa_newA <- rep(1,length(F_newA))
pa_newA[F_newA] <- p.adjust(p_[F_newA],"BH")
c3 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))
pa_BH              <- p_adjust_adaptive(p = p_, pi_0_hat = pi_0_all)
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p_adjust_adaptive(p = p_[F_0.05], pi_0_hat = pi_0_0.05)
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p_adjust_adaptive(p = p_[F_Gilb], pi_0_hat = pi_0_Tar)
pa_new          <- rep(1,length(F_new))
pa_new[F_new]   <- p_adjust_adaptive(p = p_[F_new], pi_0_hat = pi_0_new)
pa_newA         <- rep(1,length(F_newA))
pa_newA[F_newA] <- p_adjust_adaptive(p = p_[F_newA], pi_0_hat = pi_0_newA)
c4 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))

# ---------- Adjustment 5-6 p randomized 1 -------------------
set.seed(200*j)
u <- runif(n=length(f_n))
p_rand_1 <- p-u*kappa*f_n

p_ <- p_rand_1
pa_BH              <- p.adjust(p_,"BH")
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p.adjust(p_[F_0.05],"BH")
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p.adjust(p_[F_Gilb],"BH")
pa_new <- rep(1,length(F_new))
pa_new[F_new] <- p.adjust(p_[F_new],"BH")
pa_newA <- rep(1,length(F_newA))
pa_newA[F_newA] <- p.adjust(p_[F_newA],"BH")
c5 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))
pa_BH              <- p_adjust_adaptive(p = p_, pi_0_hat = pi_0_all)
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p_adjust_adaptive(p = p_[F_0.05], pi_0_hat = pi_0_0.05)
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p_adjust_adaptive(p = p_[F_Gilb], pi_0_hat = pi_0_Tar)
pa_new          <- rep(1,length(F_new))
pa_new[F_new]   <- p_adjust_adaptive(p = p_[F_new], pi_0_hat = pi_0_new)
pa_newA         <- rep(1,length(F_newA))
pa_newA[F_newA] <- p_adjust_adaptive(p = p_[F_newA], pi_0_hat = pi_0_newA)
c6 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))

# ---------- Adjustment 7-8 p randomized 2 -------------------
set.seed(300*j)
u <- runif(n=length(f_n))
p_rand_2 <- p-u*kappa*f_n

p_ <- p_rand_2
pa_BH              <- p.adjust(p_,"BH")
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p.adjust(p_[F_0.05],"BH")
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p.adjust(p_[F_Gilb],"BH")
pa_new <- rep(1,length(F_new))
pa_new[F_new] <- p.adjust(p_[F_new],"BH")
pa_newA <- rep(1,length(F_newA))
pa_newA[F_newA] <- p.adjust(p_[F_newA],"BH")
c7 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))
pa_BH              <- p_adjust_adaptive(p = p_, pi_0_hat = pi_0_all)
pa_BH_0.05         <- rep(1,length(F_0.05))
pa_BH_0.05[F_0.05] <- p_adjust_adaptive(p = p_[F_0.05], pi_0_hat = pi_0_0.05)
pa_Gilb         <- rep(1,length(F_Gilb))
pa_Gilb[F_Gilb] <- p_adjust_adaptive(p = p_[F_Gilb], pi_0_hat = pi_0_Tar)
pa_new          <- rep(1,length(F_new))
pa_new[F_new]   <- p_adjust_adaptive(p = p_[F_new], pi_0_hat = pi_0_new)
pa_newA         <- rep(1,length(F_newA))
pa_newA[F_newA] <- p_adjust_adaptive(p = p_[F_newA], pi_0_hat = pi_0_newA)
c8 <- c(sum(pa_BH<=0.05),sum(pa_BH_0.05<=0.05),sum(pa_Gilb<=0.05),sum(pa_new<=0.05),sum(pa_newA<=0.05))

# ---------- function end -------------------

#
return(cbind(fam_size,pi0,c1,c2,c3,c4,c5,c6,c7,c8))
}

```

```{r main_function_exe}
tb <- list(NA)
m1_hat_mat <- p1_hat_mat <- 1
for (i in 3+(1:43))
  {
  vec_n_u_minus_n = n_u_minus_n[,i]
  vec_n = n[,i]
  vec_N_minus_n_t = N_minus_n_t[,i]
  vec_n_t = n_t[,i]
  tb[[i]] <- proc1(i)
  cat(i,"\n")
  }
save(tb,file="tb_each.RData")
save(m1_hat_mat,p1_hat_mat,file="m1_p1_mats.RData")
```

```{r print_tables, include = T, eval = T, results='asis'}
load("tb_all.RData")
load("tb_each.RData")
load("m1_p1_mats.RData")
#-------------  10 first 2x2 tables: -----------------
# pa_BH              <- p.adjust(p,"BH")
# ind <- which(pa_BH<=0.05)
# o <- order(pa_BH[ind])
# j <- 1
# for (i in ind[o][1:10])
#   {
#   print(kable(ptable(i %% 473,1+ (i %/% 473))))
#   }
# 
#-------------  Rejections in each procedure : -----------------
colnames(tb_all) <- c("|F|","pi_0","non","non-adpt","mid","mid-adpt","r1","r1-adpt","r2","r2-adpt")
rownames(tb_all) <- c("BH","BH_0.05","Gilbert","m1est1","m1est2")

cat("\n All: \n")
kable(data.frame(tb_all),digits=4)

cat("\n Total of 'each' analysis: \n")
tbt <- matrix(0,ncol=10,nrow=5)
for (i in 3+(1:43))
  tbt <- tbt+tb[[i]]
kable(data.frame(tbt),digits=4)


## 46 variables of interest:
XrayVariableList <- c("Number.Of.Thoracic.Vertebrae","Number.Of.Lumbar.Vertebrae","Number.Of.Pelvic.Vertebrae","Number.Of.Caudal.Vertebrae", "Transitional.Vertebrae" , "Shape.Of.Vertebrae","Fusion.Of.Vertebrae", "Processes.On.Vertebrae","Maxilla","Zygomatic.Bone","Number.Of.Cervical.Vertebrae","Skull.Shape","Number.Of.Ribs.Right","Number.Of.Ribs.Left","Shape.Of.Ribcage","Shape.Of.Ribs","Rib.Fusions","Clavicle","Scapula"  ,"Humerus","Radius","Ulna","Pelvis","Femur","Tibia","Fibula","Joints","Shape.Of.Spine","Teeth","Mandible","Number.Of.Digits","Digit.Integrity","Syndactylism","Polysyndactylism","Brachydactylism","Kyphosis","Lordosis","Scoliosis","Spinous.Processes","Transverse.Processes","Fusion.Processes","Caudal.Processes","Cervical.Processes","Lumbar.Processes","Sacral.Processes","Thoracic.Processes")    

## remove 3 variables with no values:
XrayVariableList_c <- XrayVariableList[!(XrayVariableList %in% c("Spinous.Processes","Transverse.Processes","Processes.On.Vertebrae"))]

for (k in 3+(1:43))
  {
 
  colnames(tb[[k]]) <- c("|F|","pi_0","non","non-adpt","mid","mid-adpt","r1","r1-adpt","r2","r2-adpt")
rownames(tb[[k]]) <- c("BH","BH_0.05","Gilbert","m1est1","m1est2")
  print(kable(as.data.frame(tb[[k]]),digits = 4))
  }

```

```{r plots, include = T, eval = T}
## plots:
# par(mfrow=c(3,3))
# plot(sort(alpha_star),type="l",main="sorted alpha star")
# plot(sort(p),type="l",main="sorted p values")
# plot(sort(p_mid),type="l",main="sorted mid p values")
# plot(sort(p_rand_1),type="l",main="sorted rand p values")

par(mfrow=c(4,3))
for (j in 1:43)
  {
  plot(m1_hat_mat[,j+1],type="l",main=XrayVariableList_c[j])
  abline(v = tb[[3+j]][2:5,1],col=2:5)
  if (j==1) legend("topleft",lty=1,c("0.05","Tarone","m1est1","m1est2"),col=2:5)
  }
#plot(p1_hat_mat[,j+1],type="l",main="p1 estimates")
```
