---
title: 'False discovery rate procedures for discrete tests: analysis of the data from
  the Wellcome Trust Sanger Institute Mouse Genetics Project'
author: "R.H; S.Y"
date: "Mars 04, 2015"
output:
  pdf_document:
    keep_tex: yes
---

### Notations:

* Female: n..1

|  |KO  |WT  |    |
|--|:--:|:--:|:--:|
|1 |n111|n121|n1.1|
|0 |n211|n221|n2.1|
|  |n.11|n.21|n..1|

* Male: n..2

|  |KO  |WT  |    |
|--|:--:|:--:|:--:|
|1 |n112|n122|n1.2|
|0 |n212|n222|n2.2|
|  |n.12|n.22|n..2|

|  |KO |WT |   |
|--|:-:|:-:|:-:|
|1 |n11|n12|n1.|
|0 |n21|n22|n2.|
|  |n.1|n.2|n..|

|  |dra|   |   |
|--|:-:|:-:|:-:|
|w |x  |   |m  |
|b |   |   |n  |
|  |k  |   |   |

|  |Trt|Con|   |
|--|:-:|:-:|:-:|
|+ |x  |   |m1 |
|- |   |   |   |
|  |n1 |n2 |   |


### Code:

```{r knitr_options, include=FALSE}
rm(list = ls())
library(knitr)
library(partitions)
library(dplyr)
library(tidyr)
opts_chunk$set(include = FALSE,echo = FALSE, eval = FALSE)
```

```{r zero_one_data_to_222_tables}
## 46 variables of interest:
XrayVariableList <- c("Number.Of.Thoracic.Vertebrae","Number.Of.Lumbar.Vertebrae","Number.Of.Pelvic.Vertebrae","Number.Of.Caudal.Vertebrae", "Transitional.Vertebrae" , "Shape.Of.Vertebrae","Fusion.Of.Vertebrae", "Processes.On.Vertebrae","Maxilla","Zygomatic.Bone","Number.Of.Cervical.Vertebrae","Skull.Shape","Number.Of.Ribs.Right","Number.Of.Ribs.Left","Shape.Of.Ribcage","Shape.Of.Ribs","Rib.Fusions","Clavicle","Scapula"  ,"Humerus","Radius","Ulna","Pelvis","Femur","Tibia","Fibula","Joints","Shape.Of.Spine","Teeth","Mandible","Number.Of.Digits","Digit.Integrity","Syndactylism","Polysyndactylism","Brachydactylism","Kyphosis","Lordosis","Scoliosis","Spinous.Processes","Transverse.Processes","Fusion.Processes","Caudal.Processes","Cervical.Processes","Lumbar.Processes","Sacral.Processes","Thoracic.Processes")

## remove 3 variables with no values:
XrayVariableList_c <- XrayVariableList[!c(XrayVariableList %in% c("Spinous.Processes","Transverse.Processes","Processes.On.Vertebrae"))]

## read 0\1 data:
ZO_data <- tbl_df(read.csv(file = "Oct29_2014_Xray_B6N_MGPSelect_Oor1_cleanV2.csv"))

## keep variables of interest only and 3 indices : 
ZO_data_clean <- dplyr::select(ZO_data,one_of(c("Colony.Prefix","Genotype2","Gender",XrayVariableList_c)))

## create "group" variable containing the data from both "Genotype2" & "Colony.Prefix" :
ZO_data_renamed <- mutate(ZO_data_clean, Group = as.factor(ifelse(Genotype2 == "WT", "WT", paste0(Colony.Prefix, "_", Genotype2))))

## drop "Genotype2" & "Colony.Prefix" : 
ZO_data_clean2 <- mutate(ZO_data_renamed,Genotype2 = NULL, Colony.Prefix = NULL)

## reshape the data from wide (outcomes in 43 columns) to long (outcomes as variable)  
ZO_data_long <- gather(ZO_data_clean2, Outcome,zo, -Group, -Gender)

## group by ...
ZO_data_grouped <- group_by(ZO_data_long,Outcome,Gender,Group)

## ... and summarise sums, counts and NAs:
ZO_data_summariesed <- summarise(ZO_data_grouped, s = sum(zo,na.rm = T),n = sum(!is.na(zo)) , NAs = sum(is.na(zo)))

## spread to wide format - males and females in different columns:
F_only <- filter(ZO_data_summariesed, Gender == "Female")
M_only <- filter(ZO_data_summariesed, Gender == "Male")
FM_together <- full_join(F_only,M_only,by = c("Outcome","Group")) %>% ungroup()

## convert generated NAs to zero (e.g when only male group is tested the female table values are  zeros):
suppressWarnings(FM_together[is.na(FM_together)] <- 0)

## spread to wide format - KO and WT in different columns:
KOs_only <- filter(FM_together, Group != "WT")
WTs_only <- filter(FM_together, Group == "WT")
tbl_222 <- full_join(KOs_only,WTs_only,by = "Outcome")

## rename variables to 2x2x2 table notation:
tbl_222_clean <- select(tbl_222,Outcome, Group = Group.x,
         n111 = s.x.x, n.11 = n.x.x, n121 = s.x.y, n.21 = n.x.y,
         n112 = s.y.x, n.12 = n.y.x, n122 = s.y.y, n.22 = n.y.y) %>% 
  mutate(n211 = n.11 - n111, n221 = n.21 - n121,
         n212 = n.12 - n112, n222 = n.22 - n122) %>% 
  mutate(n11. = n111 + n112,
         n1.. = n111 + n112 + n121 + n122,
         n2.. = n211 + n212 + n221 + n222,
         n.1. = n111 + n211 + n112 + n212)

tbl_222_sorted <- arrange(tbl_222_clean,Outcome)
rm(list = ls()[!(ls() %in% c("tbl_222_sorted","XrayVariableList_c"))])
```

```{r functions_definitions__tests_and_multiplicity_corrections}
# ---------------- functions definitions: -----------------------------------------

# print 2X2x2 table for given row of tbl_222:
get_222_ftable <- function(row)
{
  z <- array(c(row$n111,row$n211,row$n121,row$n221,row$n112,row$n212,row$n122,row$n222), dim=c(2, 2, 2))
  #addmargins(z) 
  dimnames(z) <- list("Deformed"=c("Y","N"),"Group"=c("KO","WT"),"Gender"=c("Female","Male"))
  return(ftable(z,row.vars = 1,col.vars = c(3,2)))
}
# zelen test for interaction:
mod.zelen.test<-function (row) 
{
  z <- array(c(row$n111,row$n121,row$n211,row$n221,row$n112,row$n122,row$n212,row$n222), dim=c(2, 2, 2))
  
  # Based on chapter 10 of Nonparametric Statistical Methods, 3e Hollander, Wolfe & Chicken 
  
  if(F) z <- array(c(2, 1, 2, 5, 1, 5, 4, 1), dim=c(2, 2, 2))
  
  s <- sum(z[1, 1, ])
  k <- dim(z)[3]
  
  # blockparts is from package "partitions".  This is where large data
  # sets will be an issue.
  # Make sure that each part of the sum is no more than the column or
  # row margin total.
  bp <- numeric(0)
  for(i in 1:k) bp <- c(bp, min(sum(z[1,,i]),sum(z[,1,i])))
  a <- blockparts(bp, s)
  
  y <- numeric(0)
  for(i in 1:dim(a)[2])
  {
    is.tau.0 <- T
    x <- numeric(0)
    for(j in 1:k)
    {
      O.11 <- a[j, i]
      O.12 <- sum(z[1, , j]) - O.11
      O.21 <- sum(z[, 1, j]) - O.11
      O.22 <- sum(z[2, , j]) - O.21
      tau <- matrix(c(O.11, O.12, O.21, O.22), nrow=2, byrow=T)
      if(sum(tau == z[, , j]) < 4) is.tau.0 <- F
      n1 <- O.11 + O.12
      n2 <- O.21 + O.22
      n.1 <- O.11 + O.21
      n <- n1 + n2
      x.j <- choose(n1, O.11) * choose(n2, O.21) / choose(n, n.1)
      x <- c(x, x.j)
    }
    if(is.tau.0) tau.0 <- i
    y <- c(y, prod(x))
  }
  y <- y / sum(y)
  p <- sum(y[y<=y[tau.0]])
  alpha_star <- min(y)
  f_n <- unique(y[y==y[tau.0]])
  kappa  <- sum(y==y[tau.0])

  return(data.frame(p=p,alpha_star=alpha_star,f_n=f_n,kappa=kappa))
}

get_cond_test_pdf_supp <- function (df) 
{
  ## deformed in KO (F and M) ; white balls in hand
  xx1 <- df$n111
  xx2 <- df$n112
  ## deformed in KO and WT(F and M) : total white balls
  mm1 <- df$n111 + df$n121 # = n1.1
  mm2 <- df$n112 + df$n122 # = n1.2
  ## not deformed in KO and WT (F and  M)
  nn1 <- df$n211 + df$n221 # = n2.1
  nn2 <- df$n212 + df$n222 # = n2.2
  ## in KO deformed and not deformed(F and M) : total in hand
  kk1 <- df$n.11
  kk2 <- df$n.12
  
  BB1  <- pmin(mm1,kk1)
  BB2  <- pmin(mm2,kk2)
  AA1  <- pmax(0,kk1-nn1)
  AA2  <- pmax(0,kk2-nn2)

  pdf_list <- supp_list <- list()
  for (i in 1:nrow(df))
  {
    x <- dhyper(x = AA1[i]:BB1[i], m = mm1[i], n = nn1[i], k = kk1[i])
    y <- dhyper(x = AA2[i]:BB2[i], m = mm2[i], n = nn2[i], k = kk2[i])
    pdf_list[[i]] <- convolve(x, rev(y), type = "open")
    supp_list[[i]] <- (AA1[i]+AA2[i]):(BB1[i]+BB2[i])
  }
  
  alpha_star <- sapply(pdf_list,function(x) rev(x)[1], simplify = TRUE)
  
  return(data.frame(pdf_list=I(pdf_list),supp_list=I(supp_list),alpha_star=alpha_star))
}

get_cond_test_pvs <- function(pdf_list,supp_list,xx1,xx2)
{
  xx <- xx1+xx2
  ind_pv <- mapply(function(supp,xx) which(rev(supp)==(xx))[1],supp_list,xx)
  p   <-   mapply(function(pdf,ind_pv) sum(rev(pdf)[1:ind_pv]), pdf_list, ind_pv)
  f_n <-   mapply(function(pdf,ind_pv) rev(pdf)[ind_pv], pdf_list, ind_pv)
  kappa <- mapply(function(pdf,f_n) sum(pdf==f_n), pdf_list, f_n)   
  return(data.frame(p = p,f_n = f_n,kappa = kappa))
}

## Tarone family size, given alpha_stars: 
## finds K(alpha)=inf{1:j|m(alpha,j)<=j} where m(alpha,j)=#{i|alpha_star[i]<=alpha/j}
findK <- function(alpha_star,alpha,verbose=T)
{
  la    <- length(alpha_star) 
  m     <- vector(length=la)
  for (j in 1:la)    m[j] <- sum(alpha_star<=(alpha/j))
  if (m[1]==0) K <- 0 else
    K <- (1:la)[which(m<=(1:la))[1]]
  if (is.na(K)) stop("something is wrong, check alpha_star for NAs and findK() definition")
  if (verbose) cat("K = ",K,"\n")
  return (K)
}

## estimate pi0 conditional expectation over U[0,1] (Dickhaus 2012):
Pi_0_est_EU <- function(p,f_n,kappa,in_fam,lambda)
{
  ## size of the sub-family:
  m_tag <- sum(in_fam)
  ## logical vector of size of in_fam that indicates where p-value is between lambda and lambda + next step in pdf:
  lpl <- (lambda < p[in_fam]) & (p[in_fam] <= lambda + kappa[in_fam]*f_n[in_fam])
  ## formula for the conditional expectation over uniform (0,1):
  ecdf_lambda_EU <- (sum(p[in_fam]<=lambda))/m_tag + (sum(1 - (p[in_fam][lpl]-lambda) / (kappa[in_fam][lpl]*f_n[in_fam][lpl]) ))/m_tag
  ## and the expectation of the pi_0 estimate
  Pi_0_hat_EU <- (1-ecdf_lambda_EU)/(1-lambda)
  return(Pi_0_hat_EU)
}

## adaptive BH given pi0 estimate: 
p_adjust_adaptive <- function(p,pi_0_hat)
{
  lp <- length(p)
  i <- lp:1L
  o <- order(p, decreasing = TRUE)
  ro <- order(o)
  pmin(1, cummin(lp*pi_0_hat/i * p[o]))[ro]
}

## multiplicity adjustments
p_adjust <- function(p,alpha_star,f_n,kappa,alpha = 0.05,lambda = 0.05,index_for_seed = 1, Kvec = NULL, rr=500)
{
  ## sub families sizes and indices:
  F_alpha       <- alpha_star <= alpha
  size_F_alpha  <- sum(F_alpha)
  if (is.null(Kvec))
    K <- findK(alpha_star,alpha = 0.05)
  else
    K <- unique(Kvec)
  if (length(K)>1) stop("K>1")
  F_Gilb        <- alpha_star <= alpha/K
  
  fam_size             <- c(length(p),size_F_alpha,K)
  
  # ---------- Adjustment 1 original pv -------------------
  
  pa_BH <- p.adjust(p,"BH")
  
  ## BH on alpha_star-smaller-than-alpha:
  pa_BH_alpha <- rep(1,length(F_alpha))
  pa_BH_alpha[F_alpha] <- p.adjust(p[F_alpha],"BH")
  
  ## BH on Tarone family:
  pa_Gilb <- rep(1,length(F_Gilb))
  pa_Gilb[F_Gilb] <- p.adjust(p[F_Gilb],"BH")
  
  pa_1 <- cbind(pa_BH,pa_BH_alpha,pa_Gilb)
  
  # ---------- Adjustment 2 : adaptive pv -------------------
  
  # get pi_0 estimates for each sub family:
  pi_0_all   <- Pi_0_est_EU(p,f_n,kappa,in_fam = rep(T,length(p)),lambda = lambda)
  pi_0_alpha <- Pi_0_est_EU(p,f_n,kappa,in_fam = F_alpha,lambda = lambda)
  pi_0_Tar   <- Pi_0_est_EU(p,f_n,kappa,in_fam = F_Gilb ,lambda = lambda)
  
  pi0 <- c(pi_0_all,pi_0_alpha,pi_0_Tar)
  
  # adjustment:
  pa_BH      <- p_adjust_adaptive(p = p, pi_0_hat = pi_0_all)
  
  pa_BH_alpha <- rep(1,length(F_alpha))
  pa_BH_alpha[F_alpha] <- p_adjust_adaptive(p = p[F_alpha], pi_0_hat = pi_0_alpha)
  
  pa_Gilb    <- rep(1,length(F_Gilb))
  pa_Gilb[F_Gilb]      <- p_adjust_adaptive(p = p[F_Gilb] , pi_0_hat = pi_0_Tar)
  
  pa_2  <- cbind(pa_BH,pa_BH_alpha,pa_Gilb)
  
  # ---------- Adjustment 3 : mid pv --------------------------------
  p_mid <- p - f_n*0.5
  
  pa_BH <- p.adjust(p_mid,"BH")
  
  pa_BH_alpha <- rep(1,length(F_alpha))
  pa_BH_alpha[F_alpha] <- p.adjust(p_mid[F_alpha],"BH")
  
  pa_Gilb <- rep(1,length(F_Gilb))
  pa_Gilb[F_Gilb] <- p.adjust(p_mid[F_Gilb],"BH")
  
  pa_3  <- cbind(pa_BH,pa_BH_alpha,pa_Gilb)
  
  # ---------- Adjustment 4 : adaptive mid-pv -------------------
  pa_BH       <- p_adjust_adaptive(p = p_mid, pi_0_hat = pi_0_all)
  
  pa_BH_alpha <- rep(1,length(F_alpha))
  pa_BH_alpha[F_alpha] <- p_adjust_adaptive(p = p_mid[F_alpha], pi_0_hat = pi_0_alpha)
  
  pa_Gilb     <- rep(1,length(F_Gilb))
  pa_Gilb[F_Gilb] <- p_adjust_adaptive(p = p_mid[F_Gilb] , pi_0_hat = pi_0_Tar)
  
  pa_4 <- cbind(pa_BH,pa_BH_alpha,pa_Gilb)
  
  # ---------- Adjustment 5/6 : avg realized randomized pvalue (adp/non-adp)----------
  pa_5_cum <- pa_6_cum <- 0
  for (i in 1:rr)
  {
    # (1:500) (500+1:500) (2*500+1:500)
    set.seed(i+rr*index_for_seed)
    u <- runif(n = length(p))
    p_rand <- p - f_n*u
    
    pa_BH <- p.adjust(p_rand,"BH")
  
    pa_BH_alpha <- rep(1,length(F_alpha))
    pa_BH_alpha[F_alpha] <- p.adjust(p_rand[F_alpha],"BH")
  
    pa_Gilb <- rep(1,length(F_Gilb))
    pa_Gilb[F_Gilb] <- p.adjust(p_rand[F_Gilb],"BH")
  
    pa_5  <- cbind(pa_BH,pa_BH_alpha,pa_Gilb)
    
    pa_5_cum <- pa_5_cum + pa_5
    
    pa_BH       <- p_adjust_adaptive(p = p_rand, pi_0_hat = pi_0_all)
  
    pa_BH_alpha <- rep(1,length(F_alpha))
    pa_BH_alpha[F_alpha] <- p_adjust_adaptive(p = p_rand[F_alpha], pi_0_hat = pi_0_alpha)
  
    pa_Gilb     <- rep(1,length(F_Gilb))
    pa_Gilb[F_Gilb] <- p_adjust_adaptive(p = p_rand[F_Gilb] , pi_0_hat = pi_0_Tar)
  
    pa_6 <- cbind(pa_BH,pa_BH_alpha,pa_Gilb)
  
    pa_6_cum <- pa_6_cum + pa_6
  }
  pa_5_avg <- pa_5_cum/rr
  pa_6_avg <- pa_6_cum/rr
  
  
  out <- data.frame(pa_original_non_adp = pa_1,
             pa_original_adp = pa_2,
             pa_mid_non_adp = pa_3,
             pa_mid_adp = pa_4,
             pa_arr_non_adp = pa_5_avg,
             pa_arr_adp = pa_6_avg)

  return(cbind(out,fam_size = t(fam_size),pi0 = t(pi0)))
}

## multiplicity adjustments
p_adjust_sim <- function(p,alpha_star,f_n,alpha = 0.05,index_for_seed = 1, Kvec = NULL, rr=500)
{
  ## sub families sizes and indices:
  F_alpha       <- alpha_star <= alpha
  size_F_alpha  <- sum(F_alpha)
  if (is.null(Kvec))
    K <- findK(alpha_star,alpha)
  else
    K <- unique(Kvec)
  if (length(K)>1) stop("K>1")
  F_Gilb        <- alpha_star <= alpha/K
  fam_size             <- c(size_F_alpha,K)
  
  # ---------- Adjustment 3 : mid pv --------------------------------
  p_mid <- p - f_n*0.5
  
  pa_BH_alpha <- rep(1,length(F_alpha))
  pa_BH_alpha[F_alpha] <- p.adjust(p_mid[F_alpha],"BH")
  
  pa_Gilb <- rep(1,length(F_Gilb))
  pa_Gilb[F_Gilb] <- p.adjust(p_mid[F_Gilb],"BH")
  
  pa_3  <- cbind(pa_BH_alpha,pa_Gilb)
  
  # ---------- Adjustment 5/6 : avg realized randomized pvalue (adp/non-adp)----------
  pa_5_cum <- 0
  set.seed(index_for_seed)
  u_mat <- matrix(runif(n = length(p)*rr),nrow=length(p))
  p_rand_mat <- p -  f_n*u_mat
  
  for (j in 1:rr)
  {
    
    pa_BH_alpha <- rep(1,length(F_alpha))
    pa_BH_alpha[F_alpha] <- p.adjust(p_rand_mat[F_alpha,j],"BH")
  
    pa_Gilb <- rep(1,length(F_Gilb))
    pa_Gilb[F_Gilb] <- p.adjust(p_rand_mat[F_Gilb,j],"BH")
  
    pa_5_cum <- pa_5_cum + cbind(pa_BH_alpha,pa_Gilb)
  }
  pa_5_avg <- pa_5_cum/rr
  pa_5_avg[!F_alpha,1] <- 1
  pa_5_avg[!F_Gilb,2]  <- 1
  
  out <- data.frame(pa_mid_non_adp = pa_3,
                    pa_arr_non_adp = pa_5_avg)
  return(cbind(out,fam_size = t(fam_size)))
}
```

```{r run}

## ----  [old] get pvalue for test on marginal 2X2 tables (no female\male effect) ------
# attach(tbl_222_sorted)
# ## deformed in KO (both F and M)
# xx <- n11.
# ## deformed in KO and WT(both F and M)
# mm <- n1..
# ## not deformed in KO and WT (both F and  M)
# nn <- n2..
# ## in KO deformed and not deformed(both F and M)
# kk <- n.1.
# 
# BB  <- pmin(mm,kk)
# 
# # get pv (right tail)
# p  <- dhyper(x = xx, m = mm, n = nn, k = kk) + phyper(q = xx, m = mm, n = nn, k = kk, lower.tail = FALSE)
# 
# ## get "alpha star" (the minimum attainable p-value due to discreteness):
# alpha_star <- dhyper(x=BB, m = mm, n = nn, k = kk)
# 
# ## get the highest pdf value within the observed significance:
# f_n <- dhyper(x = xx, m = mm, n = nn, k = kk)
# 
# ## get the number of occurences of this value (usually one):
# kappa <- apply(cbind(BB,mm,nn,kk,f_n),1,
#                function(x) sum(dhyper(x = 0:x[1], m = x[2], n = x[3], k = x[4])==x[5]))

## ----  [new] get pvalue for mantel-haenszel test and interaction test: ----

tbl_pdf <- tbl_222_sorted %>% get_cond_test_pdf_supp(.)

tbl_p <-   tbl_pdf %>% data.frame(.,select(tbl_222_sorted,n111,n112)) %>% 
  {get_cond_test_pvs(pdf_list = .$pdf_list,supp_list = .$supp_list, xx1 = .$n111, xx2 = .$n112)}

tbl_p_int <- tbl_222_sorted %>% rowwise() %>%  do(mod.zelen.test(.)) 

## ----  [old] multiplicity adjustment 1: "all-outcomes-together" family: -----
alpha <- 0.05
## adjustments for the p values of the MH tests:
tbl_pa_all     <- ungroup(tbl_p) %>% do(p_adjust(.$p,.$alpha_star,.$f_n,.$kappa,alpha = 0.05))

tb_all <- tbl_pa_all %>% select(-starts_with("pi0"),-starts_with("fam")) %>% 
  summarise_each(funs(sum(.<=alpha)))

tb_all_named <- as.data.frame(matrix(tb_all,nrow = 3, dimnames = list(c("pa_BH","pa_BH_alpha","pa_Gilb"),
  c("pa_original_non_adp","pa_original_adp","pa_mid_non_adp","pa_mid_adp","pa_rand_non_adp","pa_rand_adp"))))

fam_size <- t(select(tbl_pa_all,starts_with("fam"))[1,])
pi0      <- t(select(tbl_pa_all,starts_with("pi0"))[1,])

(tb_all_2 <- cbind(tb_all_named,fam_size,pi0))

tb_rej_in_each_oc_0_05 <-  cbind(tbl_222_sorted,tbl_p) %>%
  select(Outcome ,ends_with("pa_BH_alpha")) %>%
  group_by(Outcome) %>%
  summarise_each(funs(sum(.<=alpha)))

tb_rej_in_each_oc_Gilb <-  cbind(tbl_222_sorted,tbl_p) %>%
  select(Outcome ,ends_with("pa_Gilb")) %>%
  group_by(Outcome) %>%
  summarise_each(funs(sum(.<=alpha)))

save(tb_all_2,tb_rej_in_each_oc_0_05,tb_rej_in_each_oc_Gilb,file="tables_all.RData")

## ----  [new] multiplicity adjustment 2: each-outcome-seperatly ----

## adjustments for the p values of the MH tests:
tbl_pa_each     <- cbind(select(tbl_222_sorted,Outcome),tbl_p) %>% group_by(Outcome) %>% 
  do(p_adjust(.$p,.$alpha_star,.$f_n,.$kappa,alpha = 0.05))

## adjustments for the p values of the Zelen(interaction) tests - only on the rejections of the above in mid pvalue non adaptive where alpha star smaller than alpha=0.05:
## rejection level is taken as alpha*R/{# of families} =~ 0.04
tbl_pa_int_each <- cbind(select(tbl_pa_each,Outcome,pa_mid_non_adp.pa_BH_alpha),tbl_p_int) %>%
  group_by(Outcome) %>%
  filter(pa_mid_non_adp.pa_BH_alpha <= 0.04) %>% 
  do(p_adjust(.$p,.$alpha_star,.$f_n,.$kappa,alpha = 0.05))

## results tables - number of rejected, family sizes and pi0 estimates:
tb_results_each <- tbl_pa_each %>% select(-starts_with("pi0"),-starts_with("fam")) %>% 
  summarise_each(funs(sum(.<=0.04)))
tb_results_each_fam <- tbl_pa_each %>% select(starts_with("fam")) %>% 
  summarise_each(funs(head(.,n = 1)))
tb_results_each_pi0 <- tbl_pa_each %>% select(starts_with("pi0")) %>% 
  summarise_each(funs(head(.,n = 1)))

## results tables - number of rejected, family sizes and pi0 estimates:
tb_results_each_int <- tbl_pa_int_each %>% select(-starts_with("pi0"),-starts_with("fam")) %>% 
  summarise_each(funs(sum(.<=0.05))) 
tb_results_each_int_fam <- tbl_pa_int_each %>% select(starts_with("fam")) %>% 
  summarise_each(funs(head(.,n = 1)))
tb_results_each_int_pi0 <- tbl_pa_int_each %>% select(starts_with("pi0")) %>% 
  summarise_each(funs(head(.,n = 1)))

## consice results (only families sizes and # of rejections):
xjoin <- select(tb_results_each,Outcome,main_effect_rej = pa_mid_non_adp.pa_BH_alpha) %>% 
  cbind(select(tb_results_each_fam,main_effect_size = fam_size.2),.)
yjoin <- select(tb_results_each_int,Outcome,interaction_rej = pa_mid_non_adp.pa_BH_alpha) %>% 
  cbind(select(tb_results_each_int_fam,interaction_size = fam_size.2),.)

fam_sizes_n_rej <- inner_join(xjoin,yjoin)[,c(2,1,3,4,5)]

## get significant tables:
tbl_sig <- cbind(transmute(tbl_p, p_main = p, p_mid_main = p - f_n*0.5),
                 transmute(tbl_p_int, p_int = p, p_mid_int = p - f_n*0.5),
                 tbl_222_sorted,
                 select(ungroup(tbl_pa_each),pa_MH = pa_mid_non_adp.pa_BH_alpha)) %>%
  filter(pa_MH <= 0.04) %>% 
  cbind(.,select(ungroup(tbl_pa_int_each),pa_int = pa_mid_non_adp.pa_BH_alpha)) %>% 
  filter(pa_int <= 0.05)

tbl_sig_consice <- tbl_sig[,c("Outcome","Group","p_main","p_mid_main","p_int","p_mid_int")]
tbl1 <- get_222_ftable(tbl_sig[1,])
tbl2 <- get_222_ftable(tbl_sig[2,])
tbl3 <- get_222_ftable(tbl_sig[3,])
save(fam_sizes_n_rej,tbl_sig,tbl_sig_consice,tbl1,tbl2,tbl3,file = "objects_to_report.RData")
```

### Results:

```{r print_tables, include = T, eval = T, results='asis'}
load("objects_to_report.RData")
kable(fam_sizes_n_rej)
kable(tbl_sig_consice)
kable(as.matrix(tbl1))
kable(as.matrix(tbl2))
kable(as.matrix(tbl3))
```

```{r simulation}
# get tbl_222_sorted
B <- 500
sim_result_list <- tbl_p_list <- list()
index_seed <- as.numeric(tbl_222_sorted$Outcome)
tbl_pdf <- tbl_222_sorted %>% get_cond_test_pdf_supp()
tbl_p   <-   tbl_pdf %>% data.frame(.,select(tbl_222_sorted,n111,n112)) %>% 
  {get_cond_test_pvs(pdf_list = .$pdf_list,supp_list = .$supp_list, xx1 = .$n111, xx2 = .$n112)}

installr()
%>% 
  cbind(.,select(tbl_222_sorted,Outcome))
tbl_pa_each_first <- tbl_p %>% tbl_df() %>% cbind(.,select(tbl_pdf,alpha_star)) %>%  group_by(Outcome) %>% 
  do(p_adjust(.$p,.$alpha_star,.$f_n,.$kappa,alpha = 0.05,Kvec = NULL,index_for_seed = index_seed))
tbl_K <- select(tbl_pa_each_first,fam_size.3)

for (b in 500:2000)
{ 
  cat(b,"\n")
  tbl_222_sim <- tbl_222_sorted %>%
    transmute(n111 = rhyper(nn = nrow(.),n = n211 + n221,m = n121 + n111,k = n.11),
           n112 = rhyper(nn = nrow(.),n = n212 + n222,m = n112 + n122,k = n.12))
  tbl_p <-   tbl_pdf %>% data.frame(.,select(tbl_222_sim,n111,n112)) %>% 
  {get_cond_test_pvs(pdf_list = .$pdf_list,supp_list = .$supp_list, xx1 = .$n111, xx2 = .$n112)} %>% 
  cbind(.,select(tbl_222_sorted,Outcome))
  tbl_pa_each_sim <- tbl_p %>% tbl_df() %>% cbind(.,select(tbl_pdf,alpha_star),select(tbl_K,fam_size.3)) %>%
    group_by(Outcome) %>% do(p_adjust_sim(p = .$p,alpha_star = .$alpha_star,f_n = .$f_n,alpha = 0.05,rr = 100,
                                      Kvec = .$fam_size.3,index_for_seed = index_seed+b*max(index_seed)))
  sim_result_list[[b]] <- tbl_pa_each_sim
}

save(sim_result_list[1:100],file="sim_all_true_null_100_result_list.RData")

get_n_Rej <- function(y) as.data.frame(t(colSums(y<=0.05)))
# summarize results:
nRej  <- lapply(sim_result_list, function(x) {x %>% group_by(Outcome) %>% do(get_n_Rej(.[2:5]))})
fwe  <- lapply(nRej,function(x) 1<=x[-1])
fwer <- Reduce('+', fwe)/length(nRej)
fwer_results <- cbind(unique(tbl_K),fwer)
save(fwer_results,file="fwer_results_all_true_null.RData")
```

```{r simulation_effect}
sim_result_list <- tbl_p_list <- list()
index_seed <- as.numeric(tbl_222_sorted$Outcome)
tbl_pdf <- tbl_222_sorted %>% get_cond_test_pdf_supp(.)
tbl_p <-   tbl_pdf %>% data.frame(.,select(tbl_222_sorted,n111,n112)) %>% 
  {get_cond_test_pvs(pdf_list = .$pdf_list,supp_list = .$supp_list, xx1 = .$n111, xx2 = .$n112)} %>% 
  cbind(.,select(tbl_222_sorted,Outcome))
tbl_pa_each_first <- tbl_p %>% tbl_df() %>% cbind(.,select(tbl_pdf,alpha_star)) %>%  group_by(Outcome) %>% 
  do(p_adjust(.$p,.$alpha_star,.$f_n,.$kappa,alpha = 0.05,Kvec = NULL,index_for_seed = index_seed))
tbl_K <- select(tbl_pa_each_first,fam_size.3)
library(MCMCpack)

m1 <- 100
OR <- c(2,5,10)
alpha <- 0.05
B <- 500
effect_ind <- as.vector(outer(1:m1,473*(0:42),"+"))
# container [OR,B,1=FDR\2=POWER,OC,PROC]
out <- array(dim = c(length(OR),B,2,43,4),dimnames = list(OR=OR,
                                                          b=1:B,
                                                          meassure=c("FDR","Power"),
                                                          OC=1:43,
                                                          PROC=1:4))


get_n_Rej <- function(y) as.data.frame(t(colSums(y<=alpha)))

for (k in 1:length(OR))
{
for (b in 1:B)
{ 
  cat(b,"\n")
  tbl_222_sim <- tbl_222_sorted %>%
    transmute(n111 = rhyper(nn = nrow(.),n = n211 + n221,m = n121 + n111,k = n.11),
           n112 = rhyper(nn = nrow(.),n = n212 + n222,m = n112 + n122,k = n.12))
  for (ii in effect_ind)
  {
    tbl_222_sim[ii,1]<-rnoncenhypergeom(n=1,n1=tbl_222_sorted$n.11[ii],n2=tbl_222_sorted$n.21[ii],
                                        m1=tbl_222_sorted$n111[ii]+tbl_222_sorted$n121[ii], psi = OR[k])
    tbl_222_sim[ii,2]<-rnoncenhypergeom(n=1,n1=tbl_222_sorted$n.12[ii],n2=tbl_222_sorted$n.22[ii],
                                        m1=tbl_222_sorted$n112[ii]+tbl_222_sorted$n122[ii], psi = OR[k])
  }

  tbl_p <-   tbl_pdf %>% data.frame(.,dplyr::select(tbl_222_sim,n111,n112)) %>% 
  {get_cond_test_pvs(pdf_list = .$pdf_list,supp_list = .$supp_list, xx1 = .$n111, xx2 = .$n112)} %>% 
  cbind(.,dplyr::select(tbl_222_sorted,Outcome))
  
  tbl_pa_each_sim <- tbl_p %>% tbl_df() %>%
    cbind(.,dplyr::select(tbl_pdf,alpha_star),dplyr::select(tbl_K,fam_size.3)) %>%
    group_by(Outcome) %>%
    do(p_adjust_sim(p = .$p,alpha_star = .$alpha_star,f_n = .$f_n, alpha = 0.05,rr = 100,
                    Kvec = .$fam_size.3,index_for_seed = index_seed+b*max(index_seed)))
  
  R <- tbl_pa_each_sim %>% do(get_n_Rej(.[2:5]))
  V <- tbl_pa_each_sim %>% filter(row_number()>m1)  %>%  do(get_n_Rej(.[2:5]))
  S <- tbl_pa_each_sim %>% filter(row_number()<=m1) %>%  do(get_n_Rej(.[2:5]))

  out[k,b,1,,]   <- as.matrix(V[-1]/pmax(as.matrix(R[-1]),1))
  out[k,b,2,,]   <- as.matrix(S[-1]/m1)
}
}

save(out,file="sim_w_effect_results.RData")
save.image(file="sim_w_effect_results_extras.RData")

```